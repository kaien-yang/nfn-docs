{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Neural Functional Networks (NFNs)","text":""},{"location":"#paper-arxiv","title":"Paper (arXiv)","text":"<p>This is a library of PyTorch layers for building permutation equivariant neural functional networks (NFNs). NFNs are equivariant deep learning architectures for processing weight space features, such as the weights or gradients of another neural network. We refer to the layers of an NFN as NF-Layers.</p>"},{"location":"#installation","title":"Installation","text":"<p>Simple installation from PyPI: <pre><code>pip install nfn\n</code></pre> If you want to edit source or run examples, clone the repository locally. Then run the following commands: <pre><code>git clone https://github.com/AllanYangZhou/nfn\ncd nfn\npip install -e .  # installs in editable mode\n</code></pre></p>"},{"location":"#usage","title":"Usage","text":""},{"location":"#loading-weights-as-input","title":"Loading weights as input","text":"<p>NF-Layers operate on <code>WeightSpaceFeatures</code>. The current NF-Layers are compatible with the weight spaces of simple feedforward MLPs and 2D (image) CNNs. For weight spaces of CNN classifiers we assume there is some global pooling layer (e.g., <code>nn.AdaptiveAvgPool2d(1)</code>) between the convolution and FC layers. Supporting 1D or 3D CNNs should be possible but is not currently implemented.</p> <p>To construct <code>WeightSpaceFeatures</code> from the weights of a Pytorch model, we provide the helper function <code>state_dict_to_tensors()</code>: <pre><code>from nfn.common import state_dict_to_tensors\nmodels = [...]  # batch of pytorch models\nstate_dicts = [m.state_dict() for m in models]\nwts_and_bs = [state_dict_to_tensors(sd) for sd in state_dicts]\n# Collate batch. Can be done automatically by DataLoader.\nwts_and_bs = default_collate(wts_and_bs)\nwsfeat = WeightSpaceFeatures(*wts_and_bs)\nout = nfn(wsfeat)  # NFN can now ingest WeightSpaceFeatures\n</code></pre> For now, <code>state_dict_to_tensors()</code> assumes that the <code>state_dict</code> is an ordered dictionary with keys in order <code>[weight1, bias1, ..., weightL, biasL]</code>. This is the default behavior if the <code>state_dict</code> is coming from a feedforward network that is an <code>nn.Sequential</code> model.</p>"},{"location":"#building-nfns","title":"Building NFNs","text":"<p>The NF-Layers are found in <code>nfn.layers</code>. The main data you need to build an NFN is a <code>network_spec</code>, which specifies the structure of the weight space you plan to process. If you already have a <code>WeightSpaceFeatures</code> object as above, you can use <code>network_spec_from_wsfeat</code>.</p> <pre><code>from torch import nn\nfrom nfn import layers\nfrom nfn.common import network_spec_from_wsfeat\nnetwork_spec = network_spec_from_wsfeat(wsfeat)\nnfn_channels = 32\n# io_embed: encode the input and output dimensions of the weight space feature\nnfn = nn.Sequential(\nlayers.NPLinear(network_spec, 1, nfn_channels, io_embed=True),\nlayers.TupleOp(nn.ReLU()),\nlayers.NPLinear(network_spec, nfn_channels, nfn_channels, io_embed=True),\nlayers.TupleOp(nn.ReLU()),\nlayers.HNPPool(network_spec),  # pooling layer, for invariance\nnn.Flatten(start_dim=-2),\nnn.Linear(nfn_channels * layers.HNPPool.get_num_outs(network_spec), 1)\n)\n</code></pre>"},{"location":"nfn.common/","title":"Documentation for nfn.common","text":""},{"location":"nfn.common/#nfn.common.NetworkSpec","title":"<code>nfn.common.NetworkSpec</code>  <code>dataclass</code>","text":"<p>Specifies the shape of each weight and bias. Permutable dimensions can be specified with a <code>-1</code>, since they do not need to be exactly specified.</p>"},{"location":"nfn.common/#nfn.common.data.NetworkSpec.get_io","title":"<code>get_io()</code>","text":"<p>Returns the input and output dimensions of the network.</p>"},{"location":"nfn.common/#nfn.common.data.NetworkSpec.get_num_params","title":"<code>get_num_params()</code>","text":"<p>Returns the number of parameters in the network.</p>"},{"location":"nfn.common/#nfn.common.WeightSpaceFeatures","title":"<code>nfn.common.WeightSpaceFeatures</code>","text":"<p>         Bases: <code>collections.abc.Sequence</code></p>"},{"location":"nfn.common/#nfn.common.data.WeightSpaceFeatures.__init__","title":"<code>__init__(weights, biases)</code>","text":"<p>The input for an NF-Layer.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>list or tuple</code> <p>List or tuple of tensors. The first two dimensions of each tensor must be B and C, respectively. It can be any quantity in the weight space, such as weights, gradients, activations, or sparsity masks.</p> required <code>biases</code> <code>list or tuple</code> <p>List or tuple of tensors with same length as <code>weights</code>. The first two dimensions of each tensor must be B and C, respectively.</p> required"},{"location":"nfn.common/#nfn.common.data.WeightSpaceFeatures.detach","title":"<code>detach()</code>","text":"<p>Returns a copy with detached tensors.</p>"},{"location":"nfn.common/#nfn.common.data.WeightSpaceFeatures.from_zipped","title":"<code>from_zipped(weight_and_biases)</code>  <code>classmethod</code>","text":"<p>Converts a list of (weights, biases) into a WeightSpaceFeatures object.</p>"},{"location":"nfn.common/#nfn.common.data.WeightSpaceFeatures.map","title":"<code>map(func)</code>","text":"<p>Applies <code>func</code> to each weight and bias tensor.</p>"},{"location":"nfn.common/#nfn.common.data.WeightSpaceFeatures.to","title":"<code>to(device)</code>","text":"<p>Moves all tensors to <code>device</code>.</p>"},{"location":"nfn.common/#nfn.common.state_dict_to_tensors","title":"<code>nfn.common.state_dict_to_tensors(state_dict)</code>","text":"<p>Converts a state dict into two equal-length lists, one of weights and the other of biases (or <code>None</code> if no bias is present).</p> <p>Parameters:</p> Name Type Description Default <code>state_dict</code> <code>OrderedDict</code> <p>State dict to convert. Assumes that keys are ordered according to <code>[weight1, bias1, ..., weightL, biasL]</code>.</p> required <p>Returns:</p> Type Description <code>list[Tensor]</code> <p>List of weight tensors. Length is equal to the number of layers.</p> <code>list[Tensor]</code> <p>List of bias tensors (<code>None</code> if no bias).</p>"},{"location":"nfn.common/#nfn.common.params_to_state_dicts","title":"<code>nfn.common.params_to_state_dicts(keys, wsfeat)</code>","text":"<p>Converts a WeightSpaceFeatures object into a list of corresponding state dicts, one for each batch element.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>list[str]</code> <p>Iterable of key names to use for the state dicts. Assumes that key names are ordered according to <code>[weight1, bias1, ..., weightL, biasL]</code>.</p> required <code>wsfeat</code> <code>WeightSpaceFeatures</code> <p>Weight space features to convert.</p> required <p>Returns:</p> Type Description <code>NetworkSpec</code> <p>Output network specification.</p>"},{"location":"nfn.common/#nfn.common.network_spec_from_wsfeat","title":"<code>nfn.common.network_spec_from_wsfeat(wsfeat, set_all_dims=False)</code>","text":"<p>Converts a WeightSpaceFeatures object into a NetworkSpec object.</p> <p>Parameters:</p> Name Type Description Default <code>wsfeat</code> <code>WeightSpaceFeatures</code> <p>Weight space features to convert.</p> required <code>set_all_dims</code> <code>bool</code> <p>If <code>True</code>, all dimensions in output NetworkSpec are specified (i.e.,  output NetworkSpec does not contain <code>-1</code>). Default: <code>False</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>NetworkSpec</code> <p>Output network specification.</p>"},{"location":"nfn.layers/","title":"Documentation for nfn.layers","text":""},{"location":"nfn.layers/#nfn.layers.NPPool","title":"<code>nfn.layers.NPPool</code>","text":"<p>         Bases: <code>nn.Module</code></p>"},{"location":"nfn.layers/#nfn.layers.layers.NPPool.__init__","title":"<code>__init__(network_spec, agg='mean')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>network_spec</code> <code>NetworkSpec</code> <p>Network specification.</p> required <code>agg</code> <code>str</code> <p>Type of pooling to perform. One of \"mean\", \"max\", or \"sum\". Default: \"mean\".</p> <code>'mean'</code>"},{"location":"nfn.layers/#nfn.layers.layers.NPPool.forward","title":"<code>forward(wsfeat)</code>","text":"<p>Applies the pooling operation to the input weight space features across any axis that has permutation symmetry. The pooling operation is invariant to S\\mathcal{S}S, the neuron permutation (NP) group. See Equation 5 for a complete description.</p> <p>Parameters:</p> Name Type Description Default <code>wsfeat</code> <code>WeightSpaceFeatures</code> <p>Input weight space features.</p> required <p>Returns:</p> Type Description <code>torch.Tensor</code>      .katex img {       object-fit: fill;       padding: unset;       display: block;       position: absolute;       width: 100%;       height: inherit;     }  <p>Output of pooling operation. Shape is (B,C,N)(B, C, N)(B,C,N), where NNN is the number of outputs of the global pooling layer.</p>"},{"location":"nfn.layers/#nfn.layers.layers.NPPool.get_num_outs","title":"<code>get_num_outs(network_spec)</code>  <code>staticmethod</code>","text":"<p>Returns the number of outputs of the global pooling layer.</p>"},{"location":"nfn.layers/#nfn.layers.HNPPool","title":"<code>nfn.layers.HNPPool</code>","text":"<p>         Bases: <code>nn.Module</code></p>"},{"location":"nfn.layers/#nfn.layers.layers.HNPPool.__init__","title":"<code>__init__(network_spec, agg='mean')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>network_spec</code> <code>NetworkSpec</code> <p>Network specification.</p> required <code>agg</code> <code>str</code> <p>Type of pooling to perform. One of \"mean\", \"max\", or \"sum\". Default: \"mean\".</p> <code>'mean'</code>"},{"location":"nfn.layers/#nfn.layers.layers.HNPPool.forward","title":"<code>forward(wsfeat)</code>","text":".katex img {       object-fit: fill;       padding: unset;       display: block;       position: absolute;       width: 100%;       height: inherit;     }  <p>Applies a pooling operation to the input weight space features across any axis that has permutation symmetry. The pooling operation is invariant to S~\\mathcal{\\tilde{S}}S~, the hidden neuron permutation (HNP) group. See Equation 20 for a complete description.</p> <p>Parameters:</p> Name Type Description Default <code>wsfeat</code> <code>WeightSpaceFeatures</code> <p>Input weight space features.</p> required <p>Returns:</p> Type Description <code>torch.Tensor</code>      .katex img {       object-fit: fill;       padding: unset;       display: block;       position: absolute;       width: 100%;       height: inherit;     }  <p>Output tensor with shape (B,C,N)(B, C, N)(B,C,N), where NNN is the number of outputs of the global pooling layer.</p>"},{"location":"nfn.layers/#nfn.layers.layers.HNPPool.get_num_outs","title":"<code>get_num_outs(network_spec)</code>  <code>staticmethod</code>","text":"<p>Returns the number of outputs of the global pooling layer.</p>"},{"location":"nfn.layers/#nfn.layers.Pointwise","title":"<code>nfn.layers.Pointwise</code>","text":"<p>         Bases: <code>nn.Module</code></p>"},{"location":"nfn.layers/#nfn.layers.layers.Pointwise.__init__","title":"<code>__init__(network_spec, in_channels, out_channels)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>network_spec</code> <code>NetworkSpec</code> <p>Network specification.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels of weight space features.</p> required <code>out_channels</code> <code>int</code> <p>Number of input channels of weight space features.</p> required"},{"location":"nfn.layers/#nfn.layers.layers.Pointwise.forward","title":"<code>forward(wsfeat)</code>","text":"<p>Applies a linear NF-Layer to input weight space features. The layer assumes full row and column exchangeability of the weight space features in each layer and ignores interactions between the weight space features. Only last term of Equation 3 is used in constructing this layer.</p> <p>Parameters:</p> Name Type Description Default <code>wsfeat</code> <code>WeightSpaceFeatures</code>      .katex img {       object-fit: fill;       padding: unset;       display: block;       position: absolute;       width: 100%;       height: inherit;     }  <p>Input weight space features, where each weight and bias has CinC_{in}Cin\u200b channels.</p> required <p>Returns:</p> Type Description <code>WeightSpaceFeatures</code>      .katex img {       object-fit: fill;       padding: unset;       display: block;       position: absolute;       width: 100%;       height: inherit;     }  <p>Output weight space features, where each weight and bias has CoutC_{out}Cout\u200b channels.</p>"},{"location":"nfn.layers/#nfn.layers.NPLinear","title":"<code>nfn.layers.NPLinear</code>","text":"<p>         Bases: <code>nn.Module</code></p>"},{"location":"nfn.layers/#nfn.layers.layers.NPLinear.__init__","title":"<code>__init__(network_spec, in_channels, out_channels, io_embed=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>network_spec</code> <code>NetworkSpec</code> <p>Network specification.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels of weight space features.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels of weight space features.</p> required"},{"location":"nfn.layers/#nfn.layers.layers.NPLinear.forward","title":"<code>forward(wsfeat)</code>","text":".katex img {       object-fit: fill;       padding: unset;       display: block;       position: absolute;       width: 100%;       height: inherit;     }  <p>Applies a linear NF-Layer to input weight space features. The layer is equivariant to S\\mathcal{S}S, the neuron permutation (NP) group. See Equation 3 for a complete description.</p> <p>Parameters:</p> Name Type Description Default <code>wsfeat</code> <code>WeightSpaceFeatures</code>      .katex img {       object-fit: fill;       padding: unset;       display: block;       position: absolute;       width: 100%;       height: inherit;     }  <p>Input weight space features, where each weight and bias has CinC_{in}Cin\u200b channels.</p> required <p>Returns:</p> Name Type Description <code>WeightSpaceFeatures</code> <code>WeightSpaceFeatures</code>      .katex img {       object-fit: fill;       padding: unset;       display: block;       position: absolute;       width: 100%;       height: inherit;     }  <p>Output weight space features, where each weight and bias has CoutC_{out}Cout\u200b channels.</p>"},{"location":"nfn.layers/#nfn.layers.HNPLinear","title":"<code>nfn.layers.HNPLinear</code>","text":"<p>         Bases: <code>nn.Module</code></p>"},{"location":"nfn.layers/#nfn.layers.layers.HNPLinear.__init__","title":"<code>__init__(network_spec, in_channels, out_channels)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>network_spec</code> <code>NetworkSpec</code> <p>Network specification.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels of weight space features.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels of weight space features.</p> required"},{"location":"nfn.layers/#nfn.layers.layers.HNPLinear.forward","title":"<code>forward(wsfeat)</code>","text":".katex img {       object-fit: fill;       padding: unset;       display: block;       position: absolute;       width: 100%;       height: inherit;     }  <p>Applies a linear NF-Layer to input weight space features. The layer is equivariant to S~\\mathcal{\\tilde{S}}S~, the hidden neuron permutation (HNP) group. See Appendix C for a complete description.</p> <p>Parameters:</p> Name Type Description Default <code>wsfeat</code> <code>WeightSpaceFeatures</code>      .katex img {       object-fit: fill;       padding: unset;       display: block;       position: absolute;       width: 100%;       height: inherit;     }  <p>Input weight space features, where each weight and bias has CinC_{in}Cin\u200b channels.</p> required <p>Returns:</p> Type Description <code>WeightSpaceFeatures</code>      .katex img {       object-fit: fill;       padding: unset;       display: block;       position: absolute;       width: 100%;       height: inherit;     }  <p>Output weight space features, where each weight and bias has CoutC_{out}Cout\u200b channels.</p>"}]}